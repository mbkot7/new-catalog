# Конспект лекций с формулами

---

## Лекция 07: Экспериментальные дизайны II

### 1. Квазиэкспериментальные дизайны
Квазиэкспериментальные дизайны используются, когда рандомизация невозможна или неэтична. Они обладают высокой внешней валидностью (реальный мир), но низкой внутренней валидностью (контроль факторов).  

#### 1.1. Дизайн с неэквивалентной контрольной группой
**Схема**:
\[
\begin{aligned}
&\text{Группа эксперимента: } O_1 \to X \to O_2, \\
&\text{Контрольная группа: } O_3 \to O_4.
\end{aligned}
\]
где \( O \) — наблюдения (Pretest/Posttest), \( X \) — воздействие.  

**Пример**:  
Исследуется влияние дохода на счастье. Группа с \( X \) получает увеличение дохода на \$100, а другая группа — нет. Измеряют счастье до и после.  

**Проблемы валидности**:  
- Исторические события.  
- Влияние тестирования (например, привыкание к тесту).  

#### 1.2. Прерываемый временной ряд
Используется, если невозможно найти контрольную группу. Сравниваются многократные наблюдения до и после воздействия.  

**Схема**:
\[
O_1, O_2, \ldots, O_t \to X \to O_{t+1}, O_{t+2}, \ldots, O_n.
\]

**Пример**:  
Учёт посещаемости на лекциях. До вмешательства фиксируется 4–8 пропусков, после — 0–3 пропуска.  

#### 1.3. Регрессионный разрыв
Метод основан на пороговом значении: участники выше порога получают воздействие.  

**Пример**:  
Школьники с баллом \( \geq 600 \) получают стипендию, а \( <600 \) — нет. Изучается влияние стипендии на успеваемость.  

---

## Лекция 09: Основы статистики

### 1. Дискретные случайные величины
**Матожидание**:
\[
E(X) = \sum_{i=1}^n x_i \cdot P(x_i),
\]
где \( P(x_i) \) — вероятность значения \( x_i \).  

**Дисперсия**:
\[
\text{Var}(X) = E(X^2) - [E(X)]^2.
\]

**Пример**:  
Для случайной величины с вероятностями \( P(X = 0) = 1/7 \), \( P(X = 2) = 3/7 \), \( P(X = 4) = 1/7 \), \( P(X = 6) = 2/7 \):  
\[
E(X) = 0 \cdot \frac{1}{7} + 2 \cdot \frac{3}{7} + 4 \cdot \frac{1}{7} + 6 \cdot \frac{2}{7} = 3.14.
\]

### 2. Непрерывные случайные величины
Вероятность нахождения \( X \) в интервале \([a, b]\):  
\[
P(a \leq X \leq b) = \int_a^b f(x) dx,
\]
где \( f(x) \) — плотность вероятности.  

### 3. Z-оценка
Z-оценка показывает, насколько значение отличается от среднего:  
\[
Z = \frac{X - \mu}{\sigma}.
\]

---

## Лекции 10-11: Линейная регрессия

### 1. Простая линейная регрессия
Модель выражается уравнением:  
\[
Y = aX + b,
\]
где \( a \) — наклон линии, \( b \) — пересечение с осью \( Y \).  

#### Расчёт коэффициентов:
- Наклон линии:  
\[
a = \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sum (X_i - \bar{X})^2}.
\]  
- Пересечение с осью \( Y \):  
\[
b = \bar{Y} - a\bar{X}.
\]  

#### Пример:
Дано:  
| Затраты (\( X \)) | Доход (\( Y \)) |  
|-------------------|----------------|  
| 1                 | 1              |  
| 2                 | 1              |  
| 3                 | 2              |  
| 4                 | 2              |  
| 5                 | 4              |  

- Вычислим средние:  
\[
\bar{X} = \frac{1+2+3+4+5}{5} = 3, \quad \bar{Y} = \frac{1+1+2+2+4}{5} = 2.
\]  

- Наклон:  
\[
a = \frac{(1-3)(1-2) + (2-3)(1-2) + (3-3)(2-2) + (4-3)(2-2) + (5-3)(4-2)}{(1-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (5-3)^2} = 0.7.
\]

- Пересечение:  
\[
b = 2 - 0.7 \cdot 3 = 0.9.
\]

- Итоговая модель:  
\[
Y = 0.7X + 0.9.
\]

### 2. Коэффициент детерминации (\( R^2 \))
Показывает, насколько хорошо модель объясняет данные:  
\[
R^2 = 1 - \frac{SS_{res}}{SS_{tot}},
\]
где \( SS_{res} \) — сумма квадратов остатков, \( SS_{tot} \) — общая сумма квадратов.  

#### Пример расчёта \( R^2 \):  
Для приведённого примера \( SS_{res} = 2.4 \), \( SS_{tot} = 5 \):  
\[
R^2 = 1 - \frac{2.4}{5} = 0.52 \, (52\%).
\]
